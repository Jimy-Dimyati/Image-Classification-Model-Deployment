# -*- coding: utf-8 -*-
"""ML_Image_Classification_with_Deployment_Dimyati.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JgpoN0t8OXixEcYrTPFU1gYWM3tR-z2W

# Data Diri

*   Nama : Dimyati
*   Email : dimyati197@gmail.com
*   Link Dataset : https://www.kaggle.com/datasets/madisona/translated-animals10

# Mengimpor Library
"""

# Commented out IPython magic to ensure Python compatibility.
#Impor beberapa modul Python yang dibutuhkan
import zipfile,os,glob, warnings

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np, matplotlib.pyplot as plt, matplotlib.image as mpimg
# %matplotlib inline

"""# Mempersiapkan Dataset"""

#menginstall kaggle
!pip install -q kaggle

#mengatur hak akses file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

#unduh dataset
!kaggle datasets download -d madisona/translated-animals10

"""# Mengekstraksi Dataset"""

#Ekstraksi file zip dari dataset yang dipersiapkan
!mkdir translated-animals10.zip
!unzip translated-animals10.zip -d translated-animals10
!ls translated-animals10

import shutil

ignore_animals = ['butterfly', 'cat', 'cow', 'elephant', 'horse', 'sheep', 'squirrel']

for x in ignore_animals:
  path = os.path.join(os.path.join('/content/translated-animals10/animals10/raw-img/'), x)
  shutil.rmtree(path)

#Atur lokasi dataset
dataset_dir = "translated-animals10/animals10/raw-img"
chicken_dir = os.path.join("translated-animals10/animals10/raw-img/chicken")
dog_dir = os.path.join("translated-animals10/animals10/raw-img/dog")
spider_dir = os.path.join("translated-animals10/animals10/raw-img/spider")

"""# Pemahaman Data"""

#Lihat banyaknya data yang dipergunakan
total_image = len(list(glob.iglob("translated-animals10/animals10/raw-img/*/*.*", recursive=True)))
total_chicken = len(os.listdir(chicken_dir))
total_dog = len(os.listdir(dog_dir))
total_spider = len(os.listdir(spider_dir))

print("chicken :",total_chicken) #Jumlah Gambar Chicken
print("dog :",total_dog) #Jumlah Gambar Dog
print("spider :",total_spider) #Jumlah Gambar Spider
print("All images :",total_image) #Jumlah Gambar Keseluruhan

"""# Augmentasi Gambar


"""

#Prepocessing menggunakan ImageDataGenerator

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2) #Toleransi validasi 20%

test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    validation_split = 0.2) #Toleransi validasi 20%

#Mempersiapkan train data dan valid data dari data gen
train_gen = train_datagen.flow_from_directory(
        dataset_dir,  
        target_size=(150, 150),  #Mengubah ke dalam bentuk resolusi 150x150 pixels
        batch_size=32,
        class_mode='categorical', #Menggunakan categorical karena 3 klasifikasi masalah
        subset='training')
 
valid_gen = test_datagen.flow_from_directory(
        dataset_dir, 
        target_size=(150, 150), #Mengubah ke dalam bentuk resolusi 150x150 pixels
        batch_size=32, 
        class_mode='categorical', #Menggunakan categorical karena 3 klasifikasi masalah
        subset='validation')

"""# Pemodelan"""

#Penggunaan Model
_model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.3), #Menggunakan Dropout
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
   tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

#Compile Model
_model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

_model.summary()

"""# Latih Model"""

#Penggunaan Callback
class myCallback(tf.keras.callbacks.Callback):  
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.93 and logs.get('val_accuracy')>0.93):
      print("\nAkurasi sudah mencapai atau melebihi 93%.") #Akurasi >=93%
      self.model.stop_training = True

callbacks = myCallback()

#Latih model
history_model = _model.fit(
      train_gen,  
      epochs=50,  #Jumlah iterasi
      validation_data=valid_gen, 
      validation_steps=5,  
      verbose=2, #Perintah menyebutkan jumlah epoch
      callbacks = [callbacks]
)

"""# Evaluasi Model"""

# Mengambil nilai Akurasi dan Loss
acc = history_model.history['accuracy']
val_acc = history_model.history['val_accuracy']
loss = history_model.history['loss']
val_loss = history_model.history['val_loss']

epochs = range(len(acc))

#Plot Akurasi
plt.plot(epochs, acc, 'blue', label='Akurasi Training ') #Plot dari Akurasi Training
plt.plot(epochs, val_acc, 'orange', label='Akurasi Validasi') #Plot dari Akurasi Validasi
plt.title('Akurasi Training dan Validasi') #Judul dari Plot
plt.legend(loc=0) #garis grafik
plt.figure()                                                                      
plt.show()

#Plot Loss
plt.plot(epochs, loss, 'blue', label='Loss Training ')    #Plot dari Loss Training              
plt.plot(epochs, val_loss, 'orange', label='Loss Validasi') #Plot dari Loss Validasi
plt.title('Loss Training dan Validasi') #Judul dari Plot
plt.legend(loc=0) #garis grafik
plt.figure()                                                                      
plt.show()

"""# Deployment Model"""

import pathlib
# Saving models into SavedModel format
export_dir = 'saved_model/'
tf.saved_model.save(_model, export_dir)
 
# Convert SavedModel to vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)